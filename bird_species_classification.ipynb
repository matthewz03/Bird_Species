{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic pytorch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DDP\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "\n",
    "# from torchinfo import summary\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=525, dropout=0.5):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        )\n",
    "        self.adaptive = nn.AdaptiveAvgPool2d((7,7))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(512*7*7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module, \n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        optimizer: torch.optim,\n",
    "        loss_fn,\n",
    "        save_freq: int,\n",
    "        save_path: str):\n",
    "        \n",
    "        self.local_rank = int(os.environ['LOCAL_RANK'])\n",
    "        self.global_rank = int(os.environ['RANK'])\n",
    "        self.model = model.to(self.local_rank)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "        self.save_freq = save_freq\n",
    "        self.epochs_run = 0\n",
    "        \n",
    "        if os.path.exists(save_path):\n",
    "            print('Loading Saved State')\n",
    "            self.load_saved_state(save_path)\n",
    "        \n",
    "        self.model = DDP(self.model, device_ids=[self.local_rank])\n",
    "        \n",
    "    def load_saved_state(self, save_path):\n",
    "        old_state = torch.load(save_path)\n",
    "        self.model.load_state_dict(old_state['MODEL_STATE'])\n",
    "        self.epochs_run = old_state['EPOCHS_RUN']\n",
    "        \n",
    "    def train_iter(self):\n",
    "        for X, y in self.train_loader:\n",
    "            X, y = X.to(self.local_rank), y.to(self.local_rank)\n",
    "            self.optimizer.zero_grad()\n",
    "            pred = self.model(X)\n",
    "            loss = self.loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            del X, y, pred, loss\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    def validate(self):\n",
    "        with torch.no_grad():\n",
    "            size = len(self.val_loader)\n",
    "            loss = 0\n",
    "            acc = 0\n",
    "            for X, y in self.val_loader:\n",
    "                X, y = X.to(self.local_rank), y.to(self.local_rank)\n",
    "                pred = self.model(X)\n",
    "                loss += self.loss_fn(pred, y)\n",
    "                acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "                del X, y, pred\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            acc /= size\n",
    "            loss /= size\n",
    "            print('Validation Accuracy:', str(acc))\n",
    "            print('Validation Loss:', str(loss))\n",
    "            \n",
    "    def save_state(self, epoch: int, save_path: str):\n",
    "        state = {}\n",
    "        state['MODEL_STATE'] = self.model.module.state_dict()\n",
    "        state['EPOCHS_RUN'] = epoch\n",
    "        torch.save(state, save_path)\n",
    "        print(f'Epoch {epoch}, saving model at {save_path}')\n",
    "            \n",
    "    def train_loop(self, epochs: int, save_path: str):\n",
    "        for e in range(self.epochs_run, epochs):\n",
    "            print(f'EPOCH {e} from GPU {self.global_rank}')\n",
    "            self.train_iter()\n",
    "            if self.local_rank == 0 and e % self.save_freq == 0:\n",
    "                self.save_state(e, save_path)\n",
    "\n",
    "        self.save_state(e, save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      [1, 525]                  --\n",
       "├─Sequential: 1-1                        [1, 512, 7, 7]            --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 224, 224]         1,792\n",
       "│    └─ReLU: 2-2                         [1, 64, 224, 224]         --\n",
       "│    └─Conv2d: 2-3                       [1, 64, 224, 224]         36,928\n",
       "│    └─ReLU: 2-4                         [1, 64, 224, 224]         --\n",
       "│    └─MaxPool2d: 2-5                    [1, 64, 112, 112]         --\n",
       "│    └─Conv2d: 2-6                       [1, 128, 112, 112]        73,856\n",
       "│    └─ReLU: 2-7                         [1, 128, 112, 112]        --\n",
       "│    └─Conv2d: 2-8                       [1, 128, 112, 112]        147,584\n",
       "│    └─ReLU: 2-9                         [1, 128, 112, 112]        --\n",
       "│    └─MaxPool2d: 2-10                   [1, 128, 56, 56]          --\n",
       "│    └─Conv2d: 2-11                      [1, 256, 56, 56]          295,168\n",
       "│    └─ReLU: 2-12                        [1, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-13                      [1, 256, 56, 56]          590,080\n",
       "│    └─ReLU: 2-14                        [1, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-15                      [1, 256, 56, 56]          590,080\n",
       "│    └─ReLU: 2-16                        [1, 256, 56, 56]          --\n",
       "│    └─MaxPool2d: 2-17                   [1, 256, 28, 28]          --\n",
       "│    └─Conv2d: 2-18                      [1, 512, 28, 28]          1,180,160\n",
       "│    └─ReLU: 2-19                        [1, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-20                      [1, 512, 28, 28]          2,359,808\n",
       "│    └─ReLU: 2-21                        [1, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-22                      [1, 512, 28, 28]          2,359,808\n",
       "│    └─ReLU: 2-23                        [1, 512, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-24                   [1, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-25                      [1, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-26                        [1, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-27                      [1, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-28                        [1, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-29                      [1, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-30                        [1, 512, 14, 14]          --\n",
       "│    └─MaxPool2d: 2-31                   [1, 512, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [1, 512, 7, 7]            --\n",
       "├─Sequential: 1-3                        [1, 525]                  --\n",
       "│    └─Flatten: 2-32                     [1, 25088]                --\n",
       "│    └─Dropout: 2-33                     [1, 25088]                --\n",
       "│    └─Linear: 2-34                      [1, 4096]                 102,764,544\n",
       "│    └─ReLU: 2-35                        [1, 4096]                 --\n",
       "│    └─Dropout: 2-36                     [1, 4096]                 --\n",
       "│    └─Linear: 2-37                      [1, 4096]                 16,781,312\n",
       "│    └─ReLU: 2-38                        [1, 4096]                 --\n",
       "│    └─Dropout: 2-39                     [1, 4096]                 --\n",
       "│    └─Linear: 2-40                      [1, 525]                  2,150,925\n",
       "│    └─Softmax: 2-41                     [1, 525]                  --\n",
       "==========================================================================================\n",
       "Total params: 136,411,469\n",
       "Trainable params: 136,411,469\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 108.45\n",
       "Params size (MB): 545.65\n",
       "Estimated Total Size (MB): 654.70\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = CNN().to(device)\n",
    "# summary(model, input_size=(1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Made it here\")\n",
    "init_process_group(backend='nccl')\n",
    "torch.cuda.set_device(int(os.environ['LOCAL_RANK']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './bird_dataset/train/'\n",
    "val_path = './bird_dataset/valid/'\n",
    "test_path = './bird_dataset/test/'\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size, \n",
    "    pin_memory=True, \n",
    "    shuffle=False, \n",
    "    sampler=DistributedSampler(train_dataset)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size, \n",
    "    pin_memory=True, \n",
    "    shuffle=False, \n",
    "    sampler=DistributedSampler(val_dataset)\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size, \n",
    "    pin_memory=True, \n",
    "    shuffle=False, \n",
    "    sampler=DistributedSampler(test_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = CNN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "epochs = 100\n",
    "\n",
    "save_freq = 5\n",
    "save_path = 'checkpoint.pt'\n",
    "\n",
    "DDP_model = DDPTrainer(\n",
    "    model=model, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    optimizer=optimizer, \n",
    "    loss_fn=loss_fn, \n",
    "    save_freq=save_freq,\n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "DDP_model.validate()\n",
    "# DDP_model.train_loop(epochs, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_process_group()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
